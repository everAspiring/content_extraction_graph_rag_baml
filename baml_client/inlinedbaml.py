# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGemini2Flash {\n  provider google-ai\n  retry_policy Exponential\n  options {\n    model \"gemini-2.0-flash\"\n    api_key \"AIzaSyC5gusO8hXwbP-fAFOJj2tD_favB3TL7R4\"\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.204.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "graph_rag.baml": "// We can import classes from other baml files\n// import resume from ./resume.baml\n\nclass CypherQuery {\n  query string @description(\"A valid Cypher query for the Kuzu database.\")\n}\n\nclass FinalAnswer {\n  answer string @description(\"The final, user-facing answer in natural language.\")\n}\n\n\n// This function translates a natural language question into a Cypher query\n// by showing the LLM the database schema.\nfunction GenerateCypher(question: string) -> CypherQuery {\n  client CustomGemini2Flash\n\n  prompt #\"\n    You are an expert Cypher query writer.\n    Given the Kuzu graph schema below, convert the user's question into a single, valid Cypher query.\n    Only output the query. Do not add any explanation.\n\n    ## Kuzu Graph Schema:\n    - Node: Person(name STRING, email STRING)\n    - Node: Company(name STRING)\n    - Node: Skill(name STRING)\n    - Relationship: WORKED_AT(FROM Person TO Company, title STRING, duration STRING)\n    - Relationship: HAS_SKILL(FROM Person TO Skill, level STRING)\n\n    ## User Question:\n    {{ question }}\n\n    ## Cypher Query:\n    {{ ctx.output_format }}\n  \"#\n}\n\n// This function takes the retrieved graph data and the original question\n// to synthesize a final answer.\nfunction SynthesizeAnswer(question: string, context: string) -> FinalAnswer {\n  client CustomGemini2Flash\n\n  prompt #\"\n    You are a helpful assistant.\n    Answer the user's question based *only* on the provided context information.\n    If the context does not contain the answer, say \"I do not have enough information to answer that.\"\n\n    ## Context from Graph Database:\n    {{ context }}\n\n    ## User Question:\n    {{ question }}\n\n    ## Final Answer:\n    {{ ctx.output_format }}\n  \"#\n}\n",
    "main.baml": "class PersonName {\n  first string? @alias(\"first name\") @description(\"The first name of the person.\")\n\n  last string? @alias(\"last name\") @description(\"The last name of the person.\")\n\n  middle string? @alias(\"middle name\") @description(\"The middle name of the person.\")\n\n} \n\n\nfunction ExtractPerson(record: string) -> PersonName {\n  client CustomGemini2Flash\n  prompt #\"\n    Extract the person's information using ONLY the information provided in the note.\n\n    \n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n\n    {{ record }}\n  \"#\n}\n\n\ntest ExtractPerson {\n  functions [ExtractPerson]\n  args {\n    record #\"\n    This is about Ms. Swathi P Pattapurathi.\n    \"#\n  }\n\n  @@assert(middle, {{ this.name.middle == \"P\" }})\n}\n\n\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name Person\n  email string\n  experience Experience[]\n  skills Skill[]\n  answer string? @description(\"Answer to the question asked.\")\n}\n\nclass Experience {\n  title string\n  company string\n  duration string\n  description string\n}\n\nclass Skill {\n  name string\n  level string @description(#\"\n    The proficiency level of the skill i.e., Beginner, Intermediate, Advanced\n  \"#)// e.g., Beginner, Intermediate, Advanced\n}\n\nclass Person {\n  first string @alias(\"first name\") @description(\"The first name of the person.\")\n\n  last string @alias(\"last name\") @description(\"The last name of the person.\")\n\n  middle string? @alias(\"middle name\") @description(\"The middle name of the person.\")\n\n} \n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string, question: string?) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client CustomGemini2Flash // Set GOOGLE_API_KEY to use this client.\n  \n  prompt #\"\n    Extract from this content and answer the question: \n    {{ resume }}\n\n    Question: {{ question }}\n\n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\n\n\ntest unstructured_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      John Doe, Software Engineer, lives in San Francisco. Email: john.doe@email.com, phone (555) 123-4567. \nWorked at Google as Senior Software Engineer since 2019, before that at Facebook from 2016 to 2019 as Software Engineer. \nStudied Computer Science at Stanford University, graduated in 2016. \nSkills include Python, Java, SQL, Node.js, AWS, Docker, Kubernetes, Machine Learning, NLP, CI/CD, Git, Jenkins. \nLinkedIn: linkedin.com/in/johndoe, GitHub: github.com/johndoe. \nEnjoys mentoring junior engineers and building scalable backend systems.\n  \"#,\n    question #\"\n    What is the person's area based on his phone area code?\n  \"#  \n  }\n}\n\n\ntest structured_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n     John Doe\nSOFTWARE ENGINEER\n\nCONTACT\njohn.doe@email.com\n(555) 123-4567\nSan Francisco, CA\nlinkedin.com/in/johndoe\ngithub.com/johndoe\n\nPROFILE\nExperienced software engineer with 7+ years in backend development, cloud infrastructure, and machine learning.\n\nEDUCATION\n2012-2016\nStanford University, CA\nBachelor of Science in Computer Science\n\nTECHNICAL SKILLS\n- Python, Java, SQL, Node.js\n- AWS, Docker, Kubernetes\n- Machine Learning, NLP\n- CI/CD, Git, Jenkins\n\nEXPERIENCE\n2019 – PRESENT\nSenior Software Engineer | Google\n- Led development of scalable backend systems for cloud products.\n- Designed and implemented CI/CD pipelines for microservices.\n- Mentored junior engineers and led code reviews.\n\n2016 – 2019\nSoftware Engineer | Facebook\n- Built RESTful APIs for social media analytics.\n- Collaborated with cross-functional teams to deliver new features.\n- Improved system reliability and reduced downtime by 30%.\n\nSKILLS\n- Programming: Python, Java, SQL\n- Cloud: AWS, Docker, Kubernetes\n- ML: NLP, Deep Learning\n- DevOps: CI/CD, Git, Jenkins\n\"#,\nquestion #\"\n    What is the person's name?\n  \"#  \n  }\n}\n\n\ntest ask_question {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      John Doe, Software Engineer, lives in San Francisco. Email: john.doe@email.com, phone (555) 123-4567.\nWorked at Google as Senior Software Engineer since 2019, before that at Facebook from 2016 to 2019 as Software Engineer.\nStudied Computer Science at Stanford University, graduated in 2016.\nSkills include Python, Java, SQL, Node.js, AWS, Docker, Kubernetes, Machine Learning, NLP, CI/CD, Git, Jenkins.\nLinkedIn: linkedin.com/in/johndoe, GitHub: github.com/johndoe.\nEnjoys mentoring junior engineers and building scalable backend systems.\n    \"#,\n    question #\"\n    what role do you think the person is suitable for?\n  \"#  \n  }\n}",
}

def get_baml_files():
    return _file_map